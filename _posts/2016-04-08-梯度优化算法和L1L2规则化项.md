---
layout: post
title: 梯度优化算法和L1L2规则化项
category: ml
---

### 梯度下降法 ###

梯度下降法，利用负梯度方向(或正梯度方向)来决定每次迭代的新的搜索方向，使得每次迭代能使目标函数减少或增大。梯度下降法是L2范数下的最速下降法。梯度下降法的基本形式是:

$$ \theta_{i+1}=\theta_{i} \pm \mu grad \theta $$ ,其中 $$ \mu$$称为学习速度，通常取0.1。

这个算法很容易被初始点的选择影响而陷入局部最小点。

### 随机梯度下降法 ###


### 规则化项 ###

假设代价函数为

$$ NLL(\theta,D) = - \sum_{i=0}^{\| D\|} log P(Y=y^{(i)} \| x^{(i)},\theta) $$

规则化后的代价函数就是

$$E(\theta,D) = DLL(\theta,D) + \lambda R(\theta) = DLL(\theta,D) + \lambda \sum_{j=0}^{\| \theta\|} \| \theta_{j} \|^{p}$$

通常令P的值为1或2，分别称为L1和L2。当代价函数中增添了规则化项之后会使得网络拟合函数时更加平滑。

{% include references.md %}
