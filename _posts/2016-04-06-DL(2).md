---
layout: post
title: DL(2)
category: deeplearning
---


## 稀疏自编码器 ##
逐层处理信息量不会增加，稀疏编码器中的隐藏层个数比前一层个数要少。隐藏层是一个自编码的过程，在这个过程中尽可能的保留输入的信息。

## Dropout ##
Dropout是训练神经网络模型时，防止模型过拟合的一种训练策略，主要思路是通过阻止特征检测器的共同作用来提高神经网络的性能。
在


	1.每次用输入网络的样本进行权值更新时，隐含节点以一点概率随机出现，这样权值的更新不再依赖于有固定关系的隐含节点的共同作用，阻止了某些特征仅仅在其他特征出现的情况下才有效果的情况。




{% include references.md %}
